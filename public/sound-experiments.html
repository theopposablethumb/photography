<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speak and you shall be heard</title>

    <style>
        @import url('https://fonts.googleapis.com/css2?family=Patua+One&display=swap');
        body {font-family: 'Franklin Gothic Medium', 'Arial Narrow', Arial, sans-serif; background: #111; line-height: 1.5em; color: #fefefe; margin: 0; padding: 0; font-size: 16px;}
        .container, #canvas1 {position:absolute; top: 0; left: 0; width: 100%; height: 100%; }
        h1 {font-family: 'Patua One', cursive; font-size: 2em; letter-spacing: 1px;}
        p {font-size: 1em;}
        .text {position: absolute; top: 2em; left: 0; width: 100%; text-align: center;}
        footer {position: absolute; bottom: 0; left: 0; width: 100%; text-align: center;}
        /* #canvas1 {filter: blur(3px) contrast(2);} */
    </style>
</head>
<body>
    <div class="container">
        <div class="text">
            <h1>Speak and you shall be heard</h1>
            <p>Allow your microphone to record for visual fun</p>
        </div>
        <canvas></canvas>
    </div>
    <footer>
        <p>A bit of a laugh with Javascript and HTML canvas created by Brendan Meachen</p>
    </footer>
    <script>
        const canvas = document.querySelector('canvas');
        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;

        const ctx = canvas.getContext('2d');
        //ctx.globalCompositeOperation = 'screen';

        let audioSource;
        let analyser;

        let getSound = (stream) => {
            const audioCtx = new AudioContext();
            mic = audioCtx.createMediaStreamSource(stream);
            analyser = audioCtx.createAnalyser();
            analyser.fftSize = 512;
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyser.getByteTimeDomainData(dataArray);
            mic.connect(analyser);
            analyser.connect(audioCtx.destination);

            const barWidth = 5;
            let barHeight;
            let x;

            let animate = () => {
                x = 0;
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                analyser.getByteFrequencyData(dataArray);
                drawVisualiser(bufferLength, x, barWidth, barHeight, dataArray);
                requestAnimationFrame(animate);
            }
            animate();
        };

        navigator.getUserMedia = navigator.getUserMedia
                            || navigator.webkitGetUserMedia
                            || navigator.mozGetUserMedia;
        navigator.getUserMedia({video:false,audio:true},getSound, console.log);

        let drawVisualiser = (bufferLength, x, barWidth, barHeight, dataArray) => {
            for (let i = 0; i < bufferLength; i++) {
                barHeight = dataArray[i] * 2;
                ctx.save();
                ctx.translate(canvas.width/2, canvas.height/2); // set rotation centre point
                ctx.rotate(i * Math.PI * 4 / bufferLength)
                const hue = i * 2;

                ctx.fillStyle = `hsl(${hue}, 100%, ${barHeight / 5}%)`;
                ctx.fillRect(0, 0, barWidth, barHeight);
                x += barWidth;
                ctx.restore();
            }
        }
    </script>
</body>
</html>